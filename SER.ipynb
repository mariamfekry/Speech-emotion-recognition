{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import librosa as lr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadAudio(Crema):\n",
    "    emotions = []\n",
    "    timeLines=[]\n",
    "    Audio_List=[]\n",
    "    samp_freq=[]\n",
    "\n",
    "    for wav in os.listdir(Crema):\n",
    "        path=Crema+\"\\\\\"+wav\n",
    "        audio,sampling_freq=lr.load(path,duration=2.5, offset=0.6)\n",
    "        Audio_List.append(audio)\n",
    "        samp_freq.append(sampling_freq)\n",
    "        timeLines.append(np.arange(0,len(audio))/sampling_freq)\n",
    "        info = wav.partition(\".wav\")[0].split(\"_\")\n",
    "        if info[2] == 'SAD':\n",
    "            emotions.append(0)\n",
    "        elif info[2] == 'ANG':\n",
    "            emotions.append(1)\n",
    "        elif info[2] == 'DIS':\n",
    "            emotions.append(2)\n",
    "        elif info[2] == 'FEA':\n",
    "            emotions.append(3)\n",
    "        elif info[2] == 'HAP':\n",
    "            emotions.append(4)\n",
    "        elif info[2] == 'NEU':\n",
    "            emotions.append(5)\n",
    "        else:\n",
    "            emotions.append(6)\n",
    "            \n",
    "    return Audio_List,timeLines,samp_freq,emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio_List,timeLines,samp_freq,Labels= LoadAudio(\"C:\\\\Users\\\\fruty\\\\Downloads\\\\AudioWAV\")\n",
    "print(len(Audio_List))\n",
    "print(len(timeLines))\n",
    "print(len(Labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play first ten audio and plot them \n",
    "import sounddevice as sd\n",
    "for j in range(0,6):\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.plot(timeLines[j],Audio_List[j])\n",
    "    ax.set(xlabel='Time',ylabel='sound amplitude')\n",
    "    plt.show()\n",
    "    sd.play(Audio_List[j], samp_freq[j])\n",
    "    status = sd.wait()  # Wait until file is done playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.get_duration(Audio_List[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Crossing Rate\n",
    "def zcr(data, frame_length=2048, hop_length=512):\n",
    "    zcr = lr.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "\n",
    "    return np.squeeze(zcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(data, frame_length=2048, hop_length=512):\n",
    "    en = np.array([np.sum(np.power(np.abs(data[hop:hop+frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n",
    "\n",
    "    return en / frame_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(Audio_List, samp_freq, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result,\n",
    "                        zcr(Audio_List, frame_length, hop_length),\n",
    "                        np.mean(energy(Audio_List, frame_length, hop_length),axis=0),\n",
    "                        # np.mean(entropy_of_energy(data, frame_length, hop_length), axis=0),\n",
    "                        # rmse(data, frame_length, hop_length),\n",
    "                        # spc(data, sr, frame_length, hop_length),\n",
    "                        # spc_entropy(data, sr),\n",
    "                        # spc_flux(data),\n",
    "                        # spc_rollof(data, sr, frame_length, hop_length),\n",
    "                        # chroma_stft(data, sr, frame_length, hop_length),\n",
    "                        # mel_spc(data, sr, frame_length, hop_length, flatten=True)\n",
    "                        # mfcc(data, sr, frame_length, hop_length)\n",
    "                                    ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "for i in range(len(Audio_List)):\n",
    "    features.append(extract_features(Audio_List[i],samp_freq[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df = pd.DataFrame(features)\n",
    "extracted_df[\"labels\"] = Labels\n",
    "extracted_df = extracted_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mel_spc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    mel = lr.feature.melspectrogram(y=data, sr=sr)\n",
    "    return np.squeeze(mel.T) if not flatten else np.ravel(mel.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features2(data, sr, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result,mel_spc(data, sr, frame_length, hop_length,flatten = True)))\n",
    "    print()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2=[]\n",
    "for i in range(len(Audio_List)):\n",
    "    features2.append(extract_features2(Audio_List[i],samp_freq[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_df2 = pd.DataFrame(features2)\n",
    "extracted_df2[\"labels\"] = Labels\n",
    "extracted_df2 = extracted_df2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extracted_df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "    newdf1 = np.random.rand(len(data)) < 0.7\n",
    "    train = data[newdf1]\n",
    "    test = data[~newdf1]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "validation_data=[]\n",
    "train_data,test_data=train_test_split(extracted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2=[]\n",
    "test_data2=[]\n",
    "validation_data2=[]\n",
    "train_data2,test_data2=train_test_split(extracted_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(train_data2))\n",
    "print(len(test_data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splitting(trainSet):\n",
    "  validation_data=[]\n",
    "  trainWithout_val=[]\n",
    "  output = np.random.rand(len(trainSet)) < 0.95\n",
    "  trainWithout_val = trainSet[output]\n",
    "  validation_data= trainSet[~output]\n",
    "  return validation_data,trainWithout_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data1D=[]\n",
    "trainWithout_val1D=[]\n",
    "validation_data2D=[]\n",
    "trainWithout_val2D=[]\n",
    "validation_data1D,trainWithout_val1D=validation_splitting(train_data)\n",
    "validation_data2D,trainWithout_val2D=validation_splitting(train_data2)"
   ]
  }
 ]
}